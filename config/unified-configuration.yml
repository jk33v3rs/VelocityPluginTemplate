# VeloctopusProject Unified Configuration
# 
# This configuration file demonstrates the integration of all extracted patterns
# from reference projects into a cohesive, cross-platform system.
#
# Integrated Patterns:
# - Spicord: 4-bot Discord architecture 
# - ChatRegulator: Message filtering and moderation
# - KickRedirect: Server routing and management
# - SignedVelocity: Security and authentication
# - VLobby: Lobby management and player routing
# - VPacketEvents: Packet handling and event systems
# - VelemonAId: AI integration and Python bridge
# - Discord-ai-bot: AI conversation and LLM integration

# Global Settings
project:
  name: "VeloctopusProject"
  version: "1.0.0"
  async_enabled: true
  cross_platform_enabled: true
  hot_reload_enabled: true
  performance_monitoring: true

# Platform Configuration
platforms:
  minecraft:
    enabled: true
    server_integration: "velocity"
    protocol_support: ["1.20", "1.19", "1.18"]
  
  discord:
    enabled: true
    bot_count: 4
    ai_conversation_enabled: true
    jda_version: "5.0.0"
  
  matrix:
    enabled: true
    bridge_enabled: true
    federation_support: true
  
  python_bridge:
    enabled: true
    ai_services_enabled: true
    version: "3.9+"
  
  internal_api:
    enabled: true
    rest_endpoints: true
    websocket_support: true

# Discord Integration (Spicord + Discord-ai-bot patterns)
discord_integration:
  bots:
    security_bard:
      personality: "SECURITY_BARD"
      token: "${SECURITY_BARD_TOKEN}"
      channels: ["security", "admin"]
      ai_enabled: false
      manual_responses_only: true
    
    flora:
      personality: "FLORA"
      token: "${FLORA_TOKEN}"
      channels: ["general", "help"]
      ai_enabled: true
      llm_service: "openai"
    
    may:
      personality: "MAY"
      token: "${MAY_TOKEN}"
      channels: ["support", "tickets"]
      ai_enabled: true
      llm_service: "localai"
    
    librarian:
      personality: "LIBRARIAN"
      token: "${LIBRARIAN_TOKEN}"
      channels: ["documentation", "knowledge"]
      ai_enabled: true
      llm_service: "flowise"

  llm_integration:
    enabled: true
    services:
      openai:
        api_key: "${OPENAI_API_KEY}"
        model: "gpt-4"
        max_tokens: 2048
      
      localai:
        endpoint: "http://localhost:8080"
        model: "mistral-7b"
        max_tokens: 1024
      
      flowise:
        endpoint: "http://localhost:3000"
        chatflow_id: "${FLOWISE_CHATFLOW_ID}"

# Chat Moderation (ChatRegulator patterns)
chat_moderation:
  enabled_checks:
    PROFANITY: true
    SPAM: true
    CAPS: true
    ADVERTISING: true
    REPETITION: true
    UNICODE_ABUSE: true
    COMMAND_SPAM: true

  filter_settings:
    cross_platform_filtering: true
    action_thresholds:
      warning: 3
      mute: 5
      kick: 8
      ban: 12
    
    whitelist_roles:
      - "moderator"
      - "admin"
      - "vip"

# Server Routing (KickRedirect + VLobby patterns)
server_routing:
  kick_redirect:
    mode: "INTELLIGENT"
    fallback_servers:
      - "lobby-1"
      - "lobby-2"
      - "hub"
    
    routing_rules:
      maintenance_mode: "maintenance-lobby"
      server_full: "overflow-lobby"
      server_offline: "backup-lobby"

  lobby_management:
    routing_mode: "INTELLIGENT"
    load_balancing: true
    player_preferences: true
    
    lobbies:
      main:
        capacity: 100
        priority: 1
        features: ["parkour", "shops", "games"]
      
      vip:
        capacity: 50
        priority: 2
        required_permission: "lobby.vip"

# Security (SignedVelocity patterns)
security:
  verification_level: "STANDARD"
  cross_platform_security: true
  
  authentication:
    velocity_forwarding: true
    signed_messages: true
    ip_validation: true
    
  rate_limiting:
    enabled: true
    requests_per_minute: 60
    burst_allowance: 10

# AI Integration (VelemonAId patterns)
ai_integration:
  services_enabled: true
  hardware_detection: true
  
  python_bridge:
    enabled: true
    virtual_env: "veloctopus-ai"
    requirements_file: "requirements.txt"
  
  ai_services:
    localai:
      enabled: true
      endpoint: "http://localhost:8080"
      models: ["mistral-7b", "codellama"]
    
    flowise:
      enabled: true
      endpoint: "http://localhost:3000"
      workflows: ["chat", "rag", "agent"]
    
    co_storm:
      enabled: false  # Requires special setup
      endpoint: "http://localhost:9000"

# Packet Handling (VPacketEvents patterns)
packet_handling:
  cross_platform_packets: true
  analytics_enabled: true
  
  supported_events:
    PLAYER_JOIN: true
    PLAYER_LEAVE: true
    CHAT_MESSAGE: true
    COMMAND_EXECUTION: true
    SERVER_SWITCH: true
  
  protocol_mapping:
    minecraft: "PacketEvents"
    discord: "JDA Events"
    matrix: "Matrix SDK Events"

# Performance Settings
performance:
  async_pool_size: 10
  max_concurrent_operations: 50
  cache_ttl_seconds: 300
  metrics_collection_interval: 60

# Logging Configuration
logging:
  level: "INFO"
  async_logging: true
  
  categories:
    discord: "DEBUG"
    security: "WARN"
    ai_integration: "INFO"
    packet_handling: "DEBUG"

# Development Settings
development:
  hot_reload: true
  debug_mode: false
  borrowed_code_percentage: 67
  
  reference_projects:
    - name: "Spicord"
      license: "GPL-3.0"
      patterns_used: ["multi-bot architecture", "JDA integration"]
    
    - name: "ChatRegulator"
      license: "MIT"
      patterns_used: ["message filtering", "moderation system"]
    
    - name: "KickRedirect"
      license: "MIT"
      patterns_used: ["server routing", "fallback management"]
    
    - name: "SignedVelocity"
      license: "GPL-3.0"
      patterns_used: ["security verification", "message signing"]
    
    - name: "VLobby"
      license: "GPL-3.0"
      patterns_used: ["lobby management", "player routing"]
    
    - name: "VPacketEvents"
      license: "GPL-3.0"
      patterns_used: ["packet handling", "event systems"]
    
    - name: "VelemonAId"
      license: "GPL-3.0"
      patterns_used: ["AI integration", "Python bridge"]
    
    - name: "discord-ai-bot"
      license: "MIT"
      patterns_used: ["AI conversations", "LLM integration"]
